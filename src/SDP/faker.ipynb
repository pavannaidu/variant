{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce27644",
   "metadata": {},
   "source": [
    "# Fake Data Generator \n",
    "This notebook generates fake user data with evolving schemas to demonstrate:\n",
    "- Schema evolution over time\n",
    "- Nested JSON structures\n",
    "- Optional fields appearing in different batches\n",
    "- Array and object data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81f9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install faker if needed\n",
    "%pip install faker==23.0.0 -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0706859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark session initialized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773387355a194df8b4e609abf27032dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current catalog: pavan_naidu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d180f552fbee493eb62508e092dfc428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current schema: json\n",
      "Configuration: CATALOG=pavan_naidu, SCHEMA=json, VOLUME=raw_data\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from faker import Faker\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# =============================================================================\n",
    "CATALOG = \"pavan_naidu\"                    # Unity Catalog name\n",
    "SCHEMA = \"json\"                            # Schema name within the catalog\n",
    "VOLUME = \"raw_data\"                        # Volume name for storing data\n",
    "# =============================================================================\n",
    "\n",
    "def get_spark() -> SparkSession:\n",
    "    try:\n",
    "        from databricks.connect import DatabricksSession\n",
    "        return DatabricksSession.builder.getOrCreate()\n",
    "    except Exception:\n",
    "        return SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark = get_spark()\n",
    "fake = Faker()\n",
    "\n",
    "# Set catalog and schema\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n",
    "\n",
    "print(\"âœ… Spark session initialized\")\n",
    "print(f\"Current catalog: {spark.sql('SELECT current_catalog()').collect()[0][0]}\")\n",
    "print(f\"Current schema: {spark.sql('SELECT current_schema()').collect()[0][0]}\")\n",
    "print(f\"Configuration: CATALOG={CATALOG}, SCHEMA={SCHEMA}, VOLUME={VOLUME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b05e3c",
   "metadata": {},
   "source": [
    "## Setup Volume and Folder\n",
    "\n",
    "Create Unity Catalog volume and folder for storing evolving data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68786eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Volume 'raw_data' is ready\n",
      "Volume path: /Volumes/pavan_naidu/json/raw_data\n",
      "âœ… Created folder: /Volumes/pavan_naidu/json/raw_data/users_stream\n",
      "ğŸ§¹ Cleaned existing data\n",
      "\n",
      "ğŸ“‚ Data will be saved to: /Volumes/pavan_naidu/json/raw_data/users_stream\n"
     ]
    }
   ],
   "source": [
    "# Create or verify volume exists\n",
    "try:\n",
    "    spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG}.{SCHEMA}.{VOLUME}\")\n",
    "    print(f\"âœ… Volume '{VOLUME}' is ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Volume might already exist or error: {e}\")\n",
    "\n",
    "# Get the volume path\n",
    "volume_path = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME}\"\n",
    "print(f\"Volume path: {volume_path}\")\n",
    "\n",
    "# Create a users folder in the volume\n",
    "users_folder = f\"{volume_path}/users_stream\"\n",
    "try:\n",
    "    dbutils.fs.mkdirs(users_folder)\n",
    "    print(f\"âœ… Created folder: {users_folder}\")\n",
    "except Exception as e:\n",
    "    print(f\"Folder might already exist: {e}\")\n",
    "\n",
    "# Clean existing data (optional - run if you want fresh start)\n",
    "try:\n",
    "    dbutils.fs.rm(users_folder, recurse=True)\n",
    "    dbutils.fs.mkdirs(users_folder)\n",
    "    print(\"ğŸ§¹ Cleaned existing data\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(f\"\\nğŸ“‚ Data will be saved to: {users_folder}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc439981",
   "metadata": {},
   "source": [
    "## Phase 1: Generate Basic Schema Data (Records 0-300)\n",
    "\n",
    "First batch of users with **basic schema** including:\n",
    "- Core user fields: user_id, username, email, name, age\n",
    "- Nested profile: bio, occupation, company, interests, skills\n",
    "- Nested address: street, city, state, country, coordinates\n",
    "- Nested preferences: newsletter, notifications, privacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49095492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¨ Generating Phase 1: Basic schema (300 records)...\n",
      "âœ… Generated 300 Phase 1 users\n",
      "\n",
      "ğŸ“„ Sample Phase 1 record:\n",
      "{\n",
      "  \"user_id\": \"3d378e8d-1f04-4371-82f5-65a996805bb7\",\n",
      "  \"username\": \"jonesnicole\",\n",
      "  \"email\": \"josephwilson@example.com\",\n",
      "  \"name\": \"Julie Anderson\",\n",
      "  \"age\": 38,\n",
      "  \"created_at\": \"2025-04-04 09:37:33.823373\",\n",
      "  \"last_login\": \"2025-09-26 04:09:33.067595\",\n",
      "  \"profile\": {\n",
      "    \"bio\": \"Speech respond money base list. Movement race never clear.\\nPlace attack especially of baby she. Offer his structure knowledge. Travel side image modern behavior attack.\",\n",
      "    \"occupation\": \"Public relations officer\",\n",
      "    \"company\": \"Young PLC\",\n",
      "    \"interests\": [\n",
      "      \"company\",\n",
      "      \"pattern\",\n",
      "      \"over\",\n",
      "      \"middle\"\n",
      "    ],\n",
      "    \"skills\": [\n",
      "      \"Programmer, systems\"\n",
      "    ]\n",
      "  },\n",
      "  \"address\": {\n",
      "    \"street\": \"93602 Hahn Mountains Apt. 505\",\n",
      "    \"city\": \"Meganshire\",\n",
      "    \"state\": \"Ohio\",\n",
      "    \"country\": \"Malaysia\",\n",
      "    \"postal_code\": \"88162\",\n",
      "    \"coordinates\": {\n",
      "      \"latitude\": 31.14642,\n",
      "      \"longitude\": 95.069314\n",
      "    }\n",
      "  },\n",
      "  \"preferences\": {\n",
      "    \"newsletter\": false,\n",
      "    \"notifications\": {\n",
      "      \"email\": true,\n",
      "      \"sms\": false,\n",
      "      \"push\": false,\n",
      "      \"frequency\": \"never\"\n",
      "    },\n",
      "    \"privacy\": {\n",
      "      \"profile_visible\": true,\n",
      "      \"show_email\": false,\n",
      "      \"show_location\": false\n",
      "    }\n",
      "  },\n",
      "  \"phone\": \"+1-447-448-8706x362\",\n",
      "  \"referral_code\": \"REF-7725-ubNR\",\n",
      "  \"referred_by\": \"d6d62cb4-b45b-4442-a963-953ce917a983\"\n",
      "}\n",
      "\n",
      "ğŸ’¾ Saving Phase 1: 3 batches...\n",
      "  âœ“ Saved batch 0: 100 records\n",
      "  âœ“ Saved batch 1: 100 records\n",
      "  âœ“ Saved batch 2: 100 records\n",
      "\n",
      "âœ… Phase 1 complete: 300 records saved\n"
     ]
    }
   ],
   "source": [
    "def generate_phase1_users(num_records=300):\n",
    "    \"\"\"\n",
    "    Generate Phase 1 users with BASIC SCHEMA ONLY\n",
    "    No social_media, subscription, or metrics fields\n",
    "    \"\"\"\n",
    "    users = []\n",
    "    \n",
    "    print(f\"ğŸ”¨ Generating Phase 1: Basic schema ({num_records} records)...\")\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        # Basic user structure\n",
    "        user = {\n",
    "            \"user_id\": str(fake.uuid4()),\n",
    "            \"username\": fake.user_name(),\n",
    "            \"email\": fake.email(),\n",
    "            \"name\": fake.name(),\n",
    "            \"age\": random.randint(18, 80),\n",
    "            \"created_at\": str(fake.date_time_between(start_date='-5y', end_date='now')),\n",
    "            \"last_login\": str(fake.date_time_between(start_date='-30d', end_date='now'))\n",
    "        }\n",
    "        \n",
    "        # Profile information (nested structure)\n",
    "        user[\"profile\"] = {\n",
    "            \"bio\": fake.text(max_nb_chars=200),\n",
    "            \"occupation\": fake.job(),\n",
    "            \"company\": fake.company(),\n",
    "            \"interests\": [fake.word() for _ in range(random.randint(1, 5))],\n",
    "            \"skills\": [fake.job() for _ in range(random.randint(0, 3))]\n",
    "        }\n",
    "        \n",
    "        # Address information (nested with multiple levels)\n",
    "        user[\"address\"] = {\n",
    "            \"street\": fake.street_address(),\n",
    "            \"city\": fake.city(),\n",
    "            \"state\": fake.state(),\n",
    "            \"country\": fake.country(),\n",
    "            \"postal_code\": fake.postcode(),\n",
    "            \"coordinates\": {\n",
    "                \"latitude\": float(fake.latitude()),\n",
    "                \"longitude\": float(fake.longitude())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Preferences (nested boolean flags)\n",
    "        user[\"preferences\"] = {\n",
    "            \"newsletter\": bool(random.choice([True, False])),\n",
    "            \"notifications\": {\n",
    "                \"email\": bool(random.choice([True, False])),\n",
    "                \"sms\": bool(random.choice([True, False])),\n",
    "                \"push\": bool(random.choice([True, False])),\n",
    "                \"frequency\": random.choice([\"daily\", \"weekly\", \"monthly\", \"never\"])\n",
    "            },\n",
    "            \"privacy\": {\n",
    "                \"profile_visible\": bool(random.choice([True, False])),\n",
    "                \"show_email\": bool(random.choice([True, False])),\n",
    "                \"show_location\": bool(random.choice([True, False]))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Some users have optional fields (simulate sparse data)\n",
    "        if random.random() > 0.7:\n",
    "            user[\"phone\"] = fake.phone_number()\n",
    "        \n",
    "        if random.random() > 0.8:\n",
    "            user[\"referral_code\"] = fake.bothify(text='REF-####-????')\n",
    "            user[\"referred_by\"] = str(fake.uuid4()) if random.random() > 0.5 else None\n",
    "        \n",
    "        users.append(user)\n",
    "    \n",
    "    return users\n",
    "\n",
    "# Generate Phase 1 data\n",
    "phase1_users = generate_phase1_users(300)\n",
    "print(f\"âœ… Generated {len(phase1_users)} Phase 1 users\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nğŸ“„ Sample Phase 1 record:\")\n",
    "print(json.dumps(phase1_users[0], indent=2))\n",
    "\n",
    "# Save Phase 1 data in batches\n",
    "batch_size = 100\n",
    "phase1_batches = [phase1_users[i:i+batch_size] for i in range(0, len(phase1_users), batch_size)]\n",
    "\n",
    "print(f\"\\nğŸ’¾ Saving Phase 1: {len(phase1_batches)} batches...\")\n",
    "for idx, batch in enumerate(phase1_batches):\n",
    "    batch_file = f\"{users_folder}/phase1_batch_{idx:03d}.json\"\n",
    "    jsonl_content = \"\\n\".join([json.dumps(user) for user in batch])\n",
    "    dbutils.fs.put(batch_file, jsonl_content, overwrite=True)\n",
    "    print(f\"  âœ“ Saved batch {idx}: {len(batch)} records\")\n",
    "\n",
    "print(f\"\\nâœ… Phase 1 complete: {len(phase1_users)} records saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2a109",
   "metadata": {},
   "source": [
    "## Phase 2: Add Social Media Fields (Records 300-600)\n",
    "\n",
    "Second batch adds **social_media** object with:\n",
    "- twitter handle\n",
    "- linkedin URL  \n",
    "- github profile\n",
    "\n",
    "This demonstrates **schema evolution** - new nested object appears!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2259b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¨ Generating Phase 2: Adding social_media fields (300 records)...\n",
      "âœ… Generated 300 Phase 2 users\n",
      "\n",
      "ğŸ“„ Sample Phase 2 record (notice 'social_media' field):\n",
      "{\n",
      "  \"user_id\": \"5b6fc3d5-83d9-4d32-ad64-7b7520e09071\",\n",
      "  \"name\": \"Jennifer Webb\",\n",
      "  \"email\": \"lbeasley@example.net\",\n",
      "  \"social_media\": {\n",
      "    \"twitter\": \"@yburke\",\n",
      "    \"linkedin\": null,\n",
      "    \"github\": \"github.com/kbrooks\"\n",
      "  },\n",
      "  \"...\": \"other fields...\"\n",
      "}\n",
      "\n",
      "ğŸ’¾ Saving Phase 2: 3 batches...\n",
      "  âœ“ Saved batch 0: 100 records\n",
      "  âœ“ Saved batch 1: 100 records\n",
      "  âœ“ Saved batch 2: 100 records\n",
      "\n",
      "âœ… Phase 2 complete: 300 records saved\n",
      "ğŸ”„ Schema evolved: Added 'social_media' object!\n"
     ]
    }
   ],
   "source": [
    "def generate_phase2_users(num_records=300):\n",
    "    \"\"\"\n",
    "    Generate Phase 2 users with BASIC SCHEMA + SOCIAL_MEDIA\n",
    "    This simulates schema evolution - adds new fields\n",
    "    \"\"\"\n",
    "    users = []\n",
    "    \n",
    "    print(f\"ğŸ”¨ Generating Phase 2: Adding social_media fields ({num_records} records)...\")\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        # Basic user structure (same as Phase 1)\n",
    "        user = {\n",
    "            \"user_id\": str(fake.uuid4()),\n",
    "            \"username\": fake.user_name(),\n",
    "            \"email\": fake.email(),\n",
    "            \"name\": fake.name(),\n",
    "            \"age\": random.randint(18, 80),\n",
    "            \"created_at\": str(fake.date_time_between(start_date='-5y', end_date='now')),\n",
    "            \"last_login\": str(fake.date_time_between(start_date='-30d', end_date='now'))\n",
    "        }\n",
    "        \n",
    "        # Profile, address, preferences (same as Phase 1)\n",
    "        user[\"profile\"] = {\n",
    "            \"bio\": fake.text(max_nb_chars=200),\n",
    "            \"occupation\": fake.job(),\n",
    "            \"company\": fake.company(),\n",
    "            \"interests\": [fake.word() for _ in range(random.randint(1, 5))],\n",
    "            \"skills\": [fake.job() for _ in range(random.randint(0, 3))]\n",
    "        }\n",
    "        \n",
    "        user[\"address\"] = {\n",
    "            \"street\": fake.street_address(),\n",
    "            \"city\": fake.city(),\n",
    "            \"state\": fake.state(),\n",
    "            \"country\": fake.country(),\n",
    "            \"postal_code\": fake.postcode(),\n",
    "            \"coordinates\": {\n",
    "                \"latitude\": float(fake.latitude()),\n",
    "                \"longitude\": float(fake.longitude())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        user[\"preferences\"] = {\n",
    "            \"newsletter\": bool(random.choice([True, False])),\n",
    "            \"notifications\": {\n",
    "                \"email\": bool(random.choice([True, False])),\n",
    "                \"sms\": bool(random.choice([True, False])),\n",
    "                \"push\": bool(random.choice([True, False])),\n",
    "                \"frequency\": random.choice([\"daily\", \"weekly\", \"monthly\", \"never\"])\n",
    "            },\n",
    "            \"privacy\": {\n",
    "                \"profile_visible\": bool(random.choice([True, False])),\n",
    "                \"show_email\": bool(random.choice([True, False])),\n",
    "                \"show_location\": bool(random.choice([True, False]))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # ğŸ†• NEW FIELD: Social media (this is the schema evolution!)\n",
    "        user[\"social_media\"] = {\n",
    "            \"twitter\": f\"@{fake.user_name()}\" if random.random() > 0.3 else None,\n",
    "            \"linkedin\": fake.url() if random.random() > 0.5 else None,\n",
    "            \"github\": f\"github.com/{fake.user_name()}\" if random.random() > 0.7 else None\n",
    "        }\n",
    "        \n",
    "        # Optional fields\n",
    "        if random.random() > 0.7:\n",
    "            user[\"phone\"] = fake.phone_number()\n",
    "        \n",
    "        if random.random() > 0.8:\n",
    "            user[\"referral_code\"] = fake.bothify(text='REF-####-????')\n",
    "            user[\"referred_by\"] = str(fake.uuid4()) if random.random() > 0.5 else None\n",
    "        \n",
    "        users.append(user)\n",
    "    \n",
    "    return users\n",
    "\n",
    "# Generate Phase 2 data\n",
    "phase2_users = generate_phase2_users(300)\n",
    "print(f\"âœ… Generated {len(phase2_users)} Phase 2 users\")\n",
    "\n",
    "# Show sample highlighting the new field\n",
    "print(\"\\nğŸ“„ Sample Phase 2 record (notice 'social_media' field):\")\n",
    "sample = phase2_users[0]\n",
    "print(json.dumps({\n",
    "    \"user_id\": sample[\"user_id\"],\n",
    "    \"name\": sample[\"name\"],\n",
    "    \"email\": sample[\"email\"],\n",
    "    \"social_media\": sample[\"social_media\"],  # NEW FIELD!\n",
    "    \"...\": \"other fields...\"\n",
    "}, indent=2))\n",
    "\n",
    "# Save Phase 2 data\n",
    "phase2_batches = [phase2_users[i:i+batch_size] for i in range(0, len(phase2_users), batch_size)]\n",
    "\n",
    "print(f\"\\nğŸ’¾ Saving Phase 2: {len(phase2_batches)} batches...\")\n",
    "for idx, batch in enumerate(phase2_batches):\n",
    "    batch_file = f\"{users_folder}/phase2_batch_{idx:03d}.json\"\n",
    "    jsonl_content = \"\\n\".join([json.dumps(user) for user in batch])\n",
    "    dbutils.fs.put(batch_file, jsonl_content, overwrite=True)\n",
    "    print(f\"  âœ“ Saved batch {idx}: {len(batch)} records\")\n",
    "\n",
    "print(f\"\\nâœ… Phase 2 complete: {len(phase2_users)} records saved\")\n",
    "print(\"ğŸ”„ Schema evolved: Added 'social_media' object!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf65f2",
   "metadata": {},
   "source": [
    "## Phase 3: Add Subscription & Metrics Fields (Records 600-1000)\n",
    "\n",
    "Third batch adds even more fields:\n",
    "- **subscription** object: tier, start_date, auto_renew\n",
    "- **metrics** object: login_count, posts_created, comments_made, last_activity\n",
    "\n",
    "This demonstrates **multiple schema evolutions** over time!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05982e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¨ Generating Phase 3: Adding subscription & metrics (400 records)...\n",
      "âœ… Generated 400 Phase 3 users\n",
      "\n",
      "ğŸ“„ Sample Phase 3 record (notice 'subscription' and 'metrics' fields):\n",
      "{\n",
      "  \"user_id\": \"fab6e9b8-6585-42e0-aa7b-31bd44a5b583\",\n",
      "  \"name\": \"Robin Humphrey\",\n",
      "  \"social_media\": {\n",
      "    \"twitter\": \"@brocktyler\",\n",
      "    \"linkedin\": \"http://middleton.com/\",\n",
      "    \"github\": null\n",
      "  },\n",
      "  \"subscription\": {\n",
      "    \"tier\": \"free\",\n",
      "    \"start_date\": \"2024-03-18\",\n",
      "    \"auto_renew\": false\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"login_count\": 425,\n",
      "    \"posts_created\": 234,\n",
      "    \"comments_made\": 1081,\n",
      "    \"last_activity\": \"2025-10-14 17:21:51.871194\"\n",
      "  },\n",
      "  \"...\": \"other fields...\"\n",
      "}\n",
      "\n",
      "ğŸ’¾ Saving Phase 3: 4 batches...\n",
      "  âœ“ Saved batch 0: 100 records\n",
      "  âœ“ Saved batch 1: 100 records\n",
      "  âœ“ Saved batch 2: 100 records\n",
      "  âœ“ Saved batch 3: 100 records\n",
      "\n",
      "âœ… Phase 3 complete: 400 records saved\n",
      "ğŸ”„ Schema evolved again: Added 'subscription' and 'metrics' objects!\n"
     ]
    }
   ],
   "source": [
    "def generate_phase3_users(num_records=400):\n",
    "    \"\"\"\n",
    "    Generate Phase 3 users with ALL FIELDS\n",
    "    Basic + Social Media + Subscription + Metrics\n",
    "    This is the fully evolved schema\n",
    "    \"\"\"\n",
    "    users = []\n",
    "    \n",
    "    print(f\"ğŸ”¨ Generating Phase 3: Adding subscription & metrics ({num_records} records)...\")\n",
    "    \n",
    "    for i in range(num_records):\n",
    "        # Basic user structure\n",
    "        user = {\n",
    "            \"user_id\": str(fake.uuid4()),\n",
    "            \"username\": fake.user_name(),\n",
    "            \"email\": fake.email(),\n",
    "            \"name\": fake.name(),\n",
    "            \"age\": random.randint(18, 80),\n",
    "            \"created_at\": str(fake.date_time_between(start_date='-5y', end_date='now')),\n",
    "            \"last_login\": str(fake.date_time_between(start_date='-30d', end_date='now'))\n",
    "        }\n",
    "        \n",
    "        # Profile, address, preferences\n",
    "        user[\"profile\"] = {\n",
    "            \"bio\": fake.text(max_nb_chars=200),\n",
    "            \"occupation\": fake.job(),\n",
    "            \"company\": fake.company(),\n",
    "            \"interests\": [fake.word() for _ in range(random.randint(1, 5))],\n",
    "            \"skills\": [fake.job() for _ in range(random.randint(0, 3))]\n",
    "        }\n",
    "        \n",
    "        user[\"address\"] = {\n",
    "            \"street\": fake.street_address(),\n",
    "            \"city\": fake.city(),\n",
    "            \"state\": fake.state(),\n",
    "            \"country\": fake.country(),\n",
    "            \"postal_code\": fake.postcode(),\n",
    "            \"coordinates\": {\n",
    "                \"latitude\": float(fake.latitude()),\n",
    "                \"longitude\": float(fake.longitude())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        user[\"preferences\"] = {\n",
    "            \"newsletter\": bool(random.choice([True, False])),\n",
    "            \"notifications\": {\n",
    "                \"email\": bool(random.choice([True, False])),\n",
    "                \"sms\": bool(random.choice([True, False])),\n",
    "                \"push\": bool(random.choice([True, False])),\n",
    "                \"frequency\": random.choice([\"daily\", \"weekly\", \"monthly\", \"never\"])\n",
    "            },\n",
    "            \"privacy\": {\n",
    "                \"profile_visible\": bool(random.choice([True, False])),\n",
    "                \"show_email\": bool(random.choice([True, False])),\n",
    "                \"show_location\": bool(random.choice([True, False]))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Social media (from Phase 2)\n",
    "        user[\"social_media\"] = {\n",
    "            \"twitter\": f\"@{fake.user_name()}\" if random.random() > 0.3 else None,\n",
    "            \"linkedin\": fake.url() if random.random() > 0.5 else None,\n",
    "            \"github\": f\"github.com/{fake.user_name()}\" if random.random() > 0.7 else None\n",
    "        }\n",
    "        \n",
    "        # ğŸ†• NEW FIELD: Subscription info\n",
    "        user[\"subscription\"] = {\n",
    "            \"tier\": random.choice([\"free\", \"basic\", \"premium\", \"enterprise\"]),\n",
    "            \"start_date\": str(fake.date_between(start_date='-2y', end_date='today')),\n",
    "            \"auto_renew\": bool(random.choice([True, False]))\n",
    "        }\n",
    "        \n",
    "        # ğŸ†• NEW FIELD: Usage metrics\n",
    "        user[\"metrics\"] = {\n",
    "            \"login_count\": random.randint(1, 1000),\n",
    "            \"posts_created\": random.randint(0, 500),\n",
    "            \"comments_made\": random.randint(0, 2000),\n",
    "            \"last_activity\": str(fake.date_time_between(start_date='-7d', end_date='now'))\n",
    "        }\n",
    "        \n",
    "        # Optional fields\n",
    "        if random.random() > 0.7:\n",
    "            user[\"phone\"] = fake.phone_number()\n",
    "        \n",
    "        if random.random() > 0.8:\n",
    "            user[\"referral_code\"] = fake.bothify(text='REF-####-????')\n",
    "            user[\"referred_by\"] = str(fake.uuid4()) if random.random() > 0.5 else None\n",
    "        \n",
    "        users.append(user)\n",
    "    \n",
    "    return users\n",
    "\n",
    "# Generate Phase 3 data\n",
    "phase3_users = generate_phase3_users(400)\n",
    "print(f\"âœ… Generated {len(phase3_users)} Phase 3 users\")\n",
    "\n",
    "# Show sample highlighting the new fields\n",
    "print(\"\\nğŸ“„ Sample Phase 3 record (notice 'subscription' and 'metrics' fields):\")\n",
    "sample = phase3_users[0]\n",
    "print(json.dumps({\n",
    "    \"user_id\": sample[\"user_id\"],\n",
    "    \"name\": sample[\"name\"],\n",
    "    \"social_media\": sample[\"social_media\"],\n",
    "    \"subscription\": sample[\"subscription\"],  # NEW FIELD!\n",
    "    \"metrics\": sample[\"metrics\"],  # NEW FIELD!\n",
    "    \"...\": \"other fields...\"\n",
    "}, indent=2))\n",
    "\n",
    "# Save Phase 3 data\n",
    "phase3_batches = [phase3_users[i:i+batch_size] for i in range(0, len(phase3_users), batch_size)]\n",
    "\n",
    "print(f\"\\nğŸ’¾ Saving Phase 3: {len(phase3_batches)} batches...\")\n",
    "for idx, batch in enumerate(phase3_batches):\n",
    "    batch_file = f\"{users_folder}/phase3_batch_{idx:03d}.json\"\n",
    "    jsonl_content = \"\\n\".join([json.dumps(user) for user in batch])\n",
    "    dbutils.fs.put(batch_file, jsonl_content, overwrite=True)\n",
    "    print(f\"  âœ“ Saved batch {idx}: {len(batch)} records\")\n",
    "\n",
    "print(f\"\\nâœ… Phase 3 complete: {len(phase3_users)} records saved\")\n",
    "print(\"ğŸ”„ Schema evolved again: Added 'subscription' and 'metrics' objects!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6be2c8",
   "metadata": {},
   "source": [
    "## Summary: Schema Evolution Complete\n",
    "\n",
    "View all generated files and schema evolution summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706dd1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“Š SCHEMA EVOLUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "âœ… Total records generated: 1000\n",
      "   - Phase 1 (Basic schema): 300 records\n",
      "   - Phase 2 (+ social_media): 300 records\n",
      "   - Phase 3 (+ subscription + metrics): 400 records\n",
      "\n",
      "ğŸ“‚ Data location: /Volumes/pavan_naidu/json/raw_data/users_stream\n",
      "\n",
      "ğŸ“ Files created:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase1_batch_000.json', name='phase1_batch_000.json', size=101186, modificationTime=1760591855000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase1_batch_001.json', name='phase1_batch_001.json', size=101191, modificationTime=1760591856000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase1_batch_002.json', name='phase1_batch_002.json', size=101687, modificationTime=1760591856000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase2_batch_000.json', name='phase2_batch_000.json', size=110114, modificationTime=1760592281000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase2_batch_001.json', name='phase2_batch_001.json', size=109828, modificationTime=1760592281000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase2_batch_002.json', name='phase2_batch_002.json', size=110114, modificationTime=1760592282000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase3_batch_000.json', name='phase3_batch_000.json', size=131547, modificationTime=1760592359000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase3_batch_001.json', name='phase3_batch_001.json', size=132076, modificationTime=1760592359000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase3_batch_002.json', name='phase3_batch_002.json', size=130813, modificationTime=1760592359000),\n",
       " FileInfo(path='/Volumes/pavan_naidu/json/raw_data/users_stream/phase3_batch_003.json', name='phase3_batch_003.json', size=131368, modificationTime=1760592360000)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Total files: 10\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ SCHEMA EVOLUTION TIMELINE\n",
      "======================================================================\n",
      "\n",
      "Phase 1 Schema (phase1_batch_*.json):\n",
      "  â”œâ”€â”€ user_id, username, email, name, age\n",
      "  â”œâ”€â”€ created_at, last_login\n",
      "  â”œâ”€â”€ profile {bio, occupation, company, interests[], skills[]}\n",
      "  â”œâ”€â”€ address {street, city, state, country, postal_code, coordinates{}}\n",
      "  â”œâ”€â”€ preferences {newsletter, notifications{}, privacy{}}\n",
      "  â””â”€â”€ [optional] phone, referral_code, referred_by\n",
      "\n",
      "Phase 2 Schema (phase2_batch_*.json):\n",
      "  â”œâ”€â”€ All Phase 1 fields\n",
      "  â””â”€â”€ ğŸ†• social_media {twitter, linkedin, github}\n",
      "\n",
      "Phase 3 Schema (phase3_batch_*.json):\n",
      "  â”œâ”€â”€ All Phase 1 & 2 fields\n",
      "  â”œâ”€â”€ ğŸ†• subscription {tier, start_date, auto_renew}\n",
      "  â””â”€â”€ ğŸ†• metrics {login_count, posts_created, comments_made, last_activity}\n",
      "\n",
      "======================================================================\n",
      "ğŸ¯ NEXT STEPS\n",
      "======================================================================\n",
      "\n",
      "1. Run the Lakeflow Declarative Pipeline (pipeline.ipynb)\n",
      "2. Pipeline will automatically infer schema from Phase 1 data\n",
      "3. As it processes Phase 2 & 3, schema will evolve automatically\n",
      "4. Watch the pipeline handle schema changes without failing!\n",
      "\n",
      "Pipeline will demonstrate:\n",
      "  âœ“ Automatic schema inference\n",
      "  âœ“ Schema evolution with addNewColumns mode\n",
      "  âœ“ Rescue mode for strict schema control\n",
      "  âœ“ Schema hints for type guidance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "total_records = len(phase1_users) + len(phase2_users) + len(phase3_users)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š SCHEMA EVOLUTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nâœ… Total records generated: {total_records}\")\n",
    "print(f\"   - Phase 1 (Basic schema): {len(phase1_users)} records\")\n",
    "print(f\"   - Phase 2 (+ social_media): {len(phase2_users)} records\")  \n",
    "print(f\"   - Phase 3 (+ subscription + metrics): {len(phase3_users)} records\")\n",
    "\n",
    "print(f\"\\nğŸ“‚ Data location: {users_folder}\")\n",
    "print(\"\\nğŸ“ Files created:\")\n",
    "files = dbutils.fs.ls(users_folder)\n",
    "display(files)\n",
    "\n",
    "print(f\"\\nâœ… Total files: {len(files)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ”„ SCHEMA EVOLUTION TIMELINE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Phase 1 Schema (phase1_batch_*.json):\n",
    "  â”œâ”€â”€ user_id, username, email, name, age\n",
    "  â”œâ”€â”€ created_at, last_login\n",
    "  â”œâ”€â”€ profile {bio, occupation, company, interests[], skills[]}\n",
    "  â”œâ”€â”€ address {street, city, state, country, postal_code, coordinates{}}\n",
    "  â”œâ”€â”€ preferences {newsletter, notifications{}, privacy{}}\n",
    "  â””â”€â”€ [optional] phone, referral_code, referred_by\n",
    "\n",
    "Phase 2 Schema (phase2_batch_*.json):\n",
    "  â”œâ”€â”€ All Phase 1 fields\n",
    "  â””â”€â”€ ğŸ†• social_media {twitter, linkedin, github}\n",
    "\n",
    "Phase 3 Schema (phase3_batch_*.json):\n",
    "  â”œâ”€â”€ All Phase 1 & 2 fields\n",
    "  â”œâ”€â”€ ğŸ†• subscription {tier, start_date, auto_renew}\n",
    "  â””â”€â”€ ğŸ†• metrics {login_count, posts_created, comments_made, last_activity}\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ¯ NEXT STEPS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "1. Run the Lakeflow Declarative Pipeline (pipeline.ipynb)\n",
    "2. Pipeline will automatically infer schema from Phase 1 data\n",
    "3. As it processes Phase 2 & 3, schema will evolve automatically\n",
    "4. Watch the pipeline handle schema changes without failing!\n",
    "\n",
    "Pipeline will demonstrate:\n",
    "  âœ“ Automatic schema inference\n",
    "  âœ“ Schema evolution with addNewColumns mode\n",
    "  âœ“ Rescue mode for strict schema control\n",
    "  âœ“ Schema hints for type guidance\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008bf3e",
   "metadata": {},
   "source": [
    "## Cleanup: Remove All Generated Data\n",
    "\n",
    "Run this cell to clean up all generated files and folders.  \n",
    "âš ï¸ **Warning**: This will permanently delete all data generated in this notebook!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa09c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ§¹ CLEANUP: Removing all generated data\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Current folder: /Volumes/pavan_naidu/json/raw_data/users_stream\n",
      "   Found 10 files to delete\n",
      "\n",
      "ğŸ—‘ï¸  Deleting folder: /Volumes/pavan_naidu/json/raw_data/users_stream\n",
      "   âœ… Successfully deleted all files and folder\n",
      "   âœ… Folder completely removed\n",
      "\n",
      "âœ… Cleanup complete!\n",
      "   - Removed 10 data files\n",
      "   - Removed folder: /Volumes/pavan_naidu/json/raw_data/users_stream\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¡ TIP: You can re-run the data generation cells to create fresh data\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cleanup script to remove all generated data\n",
    "import time\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ§¹ CLEANUP: Removing all generated data\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # List files before cleanup\n",
    "    print(f\"\\nğŸ“‚ Current folder: {users_folder}\")\n",
    "    files_before = dbutils.fs.ls(users_folder)\n",
    "    print(f\"   Found {len(files_before)} files to delete\")\n",
    "    \n",
    "    # Remove all files and the folder\n",
    "    print(f\"\\nğŸ—‘ï¸  Deleting folder: {users_folder}\")\n",
    "    dbutils.fs.rm(users_folder, recurse=True)\n",
    "    print(\"   âœ… Successfully deleted all files and folder\")\n",
    "    \n",
    "    # Verify deletion\n",
    "    try:\n",
    "        remaining_files = dbutils.fs.ls(users_folder)\n",
    "        print(f\"   âš ï¸  Warning: {len(remaining_files)} files still exist\")\n",
    "    except Exception:\n",
    "        print(\"   âœ… Folder completely removed\")\n",
    "    \n",
    "    print(f\"\\nâœ… Cleanup complete!\")\n",
    "    print(f\"   - Removed {len(files_before)} data files\")\n",
    "    print(f\"   - Removed folder: {users_folder}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error during cleanup: {e}\")\n",
    "    print(\"   The folder may not exist or may already be deleted\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ’¡ TIP: You can re-run the data generation cells to create fresh data\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce18123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
